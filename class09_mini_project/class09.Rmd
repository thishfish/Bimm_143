---
title: "class09"
author: "Thisha Thiagarajan A15474979"
date: "10/26/2021"
output:
  pdf_document: default
  html_document: default
---

# Preparing the Data

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
#omit first column (diagnosis) since that is essentially the answer 
wisc.data <- wisc.df[,-1]
#save the diagnosis data to check our work later 
diagnosis <- factor(wisc.df[,1])
```

> **Q1. How many observations are in this data set?**

Using the dim() function, I determined that there are 569 observations in the data set.

```{r}
dim(wisc.data)
```

> **Q2. How many obervations have a malignant diagnosis?**

Using the length() function combined with the grep() function, I determined that there are 47.

```{r}
#length totals the grep() to get the # obs with "M"
length(grep("M", diagnosis))
```

> \*\*Q3. How many variables/features in the data are suffixed with \_mean?\*\*

There are 10 features in the data that are suffixed with \_mean. I used the colnames(), length(), and grep() functions to determine this.

```{r}
#create vector with just the colnames 
colnam <- colnames(wisc.data)
#total number of colnames with _mean
length(grep("_mean",colnam))
```

# Principal Component Analysis

Determine if the data needs to be scaled. We do need to set scale = TRUE since the columns data are on different scales.

```{r}
#determine col means 
colMeans(wisc.data)
#determine standard deviation 
apply(wisc.data,2,sd)
```

## Execute PCA

```{r}
#pca
wisc.pr <- prcomp(wisc.data, scale = TRUE)
#print summary info 
summary(wisc.pr)
```

> **Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?**

44.27% of the original variance is captures by the first principal component.

> **Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?**

PC1, PC2, PC3 are needed to describe at least 70% (72.6% to be exact).

> **Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?**

The first 7 PC components are needed to describe at least 90% (91% to be exact).

## Interpret PCA

Create a biplot

```{r}
biplot(wisc.pr)
```

> **Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?**

This plot is difficult for me to understand since there are many data points. The points overlap throughout the plot, making it difficult to even see labels to interpret the results. Overall, there are too many data points to effectively use this plot to interpret results. Thus, I think we will need to use other techniques.

Plot of PCA1 vs PCA2

```{r}
plot(x = wisc.pr$x[,1], y = wisc.pr$x[,2], col = diagnosis , 
     xlab = "PC1", ylab = "PC2")

#generic color palette sets 0 = black, 1 = red 

```

> **Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?**

Both plots have similar subgroups (benign vs malignant!, this is the data we were hoping to get). The first plot (PC1 vs PC2) has a cleaner separation between the two subgroups and this is most likely due to how PC2 accounts for a larger proportion of variance in the data than PC3.

```{r}
plot(x = wisc.pr$x[,1], y = wisc.pr$x[,3], col = diagnosis , 
     xlab = "PC1", ylab = "PC3")
```

## Create ggplot

```{r}
# ggplot needs data frame
df<- as.data.frame(wisc.pr$x)

# load
library(ggplot2)

# plot
ggplot(df) + 
  aes(x=PC1, y=PC2, col=diagnosis) +
  geom_point() 

```

## Understand Variance

```{r}
#variance of each PC
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# scree plot (scatterplot)
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
#scree plot (barplot)
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

Use "factoextra" package to make a fancy scree plot.

```{r}
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

> **Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr\$rotation\[,1\]) for the feature concave.points_mean?**

For pca1, the component of the loading vector for the feature concave.points_mean is -0.2608538.

```{r}
barplot(wisc.pr$rotation[,1])
pca1_loadingvector <- wisc.pr$rotation[,1]
pca1_loadingvector["concave.points_mean"]

##or you can also just use wisc.pr$rotation["concave.points_mean",1] 
```

> **Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?**

5 principal components are required to explain 80% of the variance of the data. I revisited the summary of wisc.pr to determine this.

```{r}
summary(wisc.pr)
```

# Hierarchical Clustering

Remember, with this type of clustering you need to specify the number of groups.

```{r}
#scale data
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method = "complete")
#plot hclust
plot(wisc.hclust)
```

> **Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?**

At a height of 19.

```{r}
plot(wisc.hclust)
#abline() will draw the line 
abline(h = 19, col="red", lty=2)
```

## Selecting Number of Clusters 

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 4)
table(wisc.hclust.clusters, diagnosis)
```
Cluster 1 and 3 are somewhat split into the benign and malignant clusters, but its not very helpful data. 

> **Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?**

I tried all the different number of clusters between 2 and 10 and I was not able to find a better cluster vs. diagnosis match. 

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 5)
table(wisc.hclust.clusters, diagnosis)
```

## Using different methods

There are 4 different methods; these include "single", "complete", "average" and (my favorite) "ward.D2".

> **Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.**

Ward.D2 has the the most balanced dendrogram. As explained, it creates groups such that the variance is minimized within clusters. All the other dendrograms are heavily skewed to one side. 

```{r}
#method = single
plot(hclust(data.dist, method = "single"))
#method = complete
plot(wisc.hclust)
#method = average
plot(hclust(data.dist, method = "average"))
#method = ward.D2
plot(hclust(data.dist, method = "ward.D2"))
```


# Combining Methods

We take the results of our PCA analysis and cluster in this space `wisc.pr$x`. 

```{r}
#summary(wisc.pr)
#hclust using PCA data of frist 3 PCs (70% variance reached)
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method = "ward.D2")
head(wisc.pr$x[,1:3])

#plot the dendrogram
plot(wisc.pr.hclust)
abline(h=60, col="red")

#cut the tree into k=2 groups 
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

Cross table compare of diagnosis and my cluster groups 

```{r}
table(diagnosis, grps)
```

> **Q15. How well does the newly created model with two clusters separate out the two diagnoses?**

This method is a lot more effective. Using similar processes we can continue to determine the best method for the specific data set in real life to best analyze data (will never be perfect). These groups can be easily split into false positive, true positive, false negative, and true negative as well. 

> **Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.**

The combined method is significantly better than just using hclust. We did not use kmeans so I did not compare it here. 

```{r}
#hclust + pca
table(grps, diagnosis)
#just hclust
table(wisc.hclust.clusters, diagnosis)
```

Extra: Let's visualize the cluster groups/diagnosis groups. 

```{r}
plot(wisc.pr$x[,1:3], col=grps)
plot(wisc.pr$x[,1:3], col=diagnosis)
```

Try a 3D visual. 

```{r}
library(rgl)
plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=grps)
rglwidget(width = 400, height = 400) 
```

# Sensitivity/ Specificity 

**Sensitivity** refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

**Specificity** relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).


> **Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?*** 

The combined method of using hclust and pca resulted in the best sensitivity (as shown below). Just using hclust alone resulted in the best specificity. In terms of this example, I do think the sensitivity is a more important aspect. 

Calculate sensitivity TP/(TP+FN): 

```{r}
# hclust + pca = 0.844
179/(179 + 33)

# hclust = 0.804
165/(165 + 40)

```
Calculate specificity TN/(TN+FN): 

```{r}
#hclust + pca = 0.932
333/(333+24)

#hclust = 0.966
343/(343 + 12)
```

# Prediction

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc

plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> **Q18. Which of these new patients should we prioritize for follow up based on your results?**

I would prioritize patient 2 since using the prediction, we can see that this patients results are most similar to the other results of malignant patients. 

